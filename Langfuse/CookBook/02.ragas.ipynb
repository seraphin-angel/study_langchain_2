{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ラガスを使用したRAGパイプラインの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 30/30 [00:00<00:00, 2174.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")['baseline']\n",
    "\n",
    "# 'ground_truths' を 'ground_truth' に変更\n",
    "def rename_ground_truths(example):\n",
    "    example['ground_truth'] = example.pop('ground_truths')\n",
    "    return example\n",
    "\n",
    "fiqa_eval = fiqa_eval.map(rename_ground_truths)\n",
    "\n",
    "fiqa_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision\n",
    "from ragas.metrics.critique import harmfulness\n",
    " \n",
    "# metrics you chose\n",
    "metrics = [faithfulness, answer_relevancy, context_precision, harmfulness]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
    " \n",
    " \n",
    "# util function to init Ragas Metrics\n",
    "def init_ragas_metrics(metrics, llm, embedding):\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, MetricWithLLM):\n",
    "            metric.llm = llm\n",
    "        if isinstance(metric, MetricWithEmbeddings):\n",
    "            metric.embeddings = embedding\n",
    "        run_config = RunConfig()\n",
    "        metric.init(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    " \n",
    "# wrappers\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    " \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    " \n",
    "init_ragas_metrics(\n",
    "    metrics,\n",
    "    llm=LangchainLLMWrapper(llm),\n",
    "    embedding=LangchainEmbeddingsWrapper(emb),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレースでスコアを付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How to deposit a cheque issued to an associate in my business into my business account?',\n",
       " '\\nThe best way to deposit a cheque issued to an associate in your business into your business account is to open a business account with the bank. You will need a state-issued \"dba\" certificate from the county clerk\\'s office as well as an Employer ID Number (EIN) issued by the IRS. Once you have opened the business account, you can have the associate sign the back of the cheque and deposit it into the business account.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = fiqa_eval[0]\n",
    "row['question'], row['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    " \n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def score_with_ragas(query, chunks, answer, ground_truth):\n",
    "    scores = {}\n",
    "    for m in metrics:\n",
    "        print(f\"calculating {m.name}\")\n",
    "        scores[m.name] = await m.ascore(\n",
    "            row={\"question\": query, \"contexts\": chunks, \"answer\": answer, \"ground_truth\": ground_truth}  # 修正済み\n",
    "        )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating faithfulness\n",
      "calculating answer_relevancy\n",
      "calculating context_precision\n",
      "calculating harmfulness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.6,\n",
       " 'answer_relevancy': 0.9413758834646305,\n",
       " 'context_precision': 0.9999999999,\n",
       " 'harmfulness': 0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new trace when you get a question\n",
    "question = row['question']\n",
    "trace = langfuse.trace(name = \"rag\")\n",
    " \n",
    "# retrieve the relevant chunks\n",
    "# chunks = get_similar_chunks(question)\n",
    "contexts = row['contexts']\n",
    "# pass it as span\n",
    "trace.span(\n",
    "    name = \"retrieval\", input={'question': question}, output={'contexts': contexts}\n",
    ")\n",
    " \n",
    "# use llm to generate a answer with the chunks\n",
    "# answer = get_response_from_llm(question, chunks)\n",
    "answer = row['answer']\n",
    "trace.span(\n",
    "    name = \"generation\", input={'question': question, 'contexts': contexts}, output={'answer': answer}\n",
    ")\n",
    "\n",
    "ground_truth = row['ground_truth']\n",
    "trace.span(\n",
    "    name = \"generation\", input={'question': question, 'contexts': contexts}, output={'ground_truth': ground_truth}  # 修正済み\n",
    ")\n",
    "\n",
    "\n",
    "# compute scores for the question, context, answer tuple\n",
    "ragas_scores = await score_with_ragas(question, contexts, answer, ground_truth)\n",
    "ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the scores\n",
    "for m in metrics:\n",
    "    trace.score(name=m.name, value=ragas_scores[m.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチとしてスコアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiqa traces\n",
    "for interaction in fiqa_eval.select(range(10, 20)):\n",
    "    trace = langfuse.trace(name = \"rag\")\n",
    "    trace.span(\n",
    "        name = \"retrieval\",\n",
    "        input={'question': question},\n",
    "        output={'contexts': contexts}\n",
    "    )\n",
    "    trace.span(\n",
    "        name = \"generation\",\n",
    "        input={'question': question, 'contexts': contexts},\n",
    "        output={'answer': answer}\n",
    "    )\n",
    " \n",
    "# await that Langfuse SDK has processed all events before trying to retrieve it in the next step\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traces(name=None, limit=None, user_id=None):\n",
    "    all_data = []\n",
    "    page = 1\n",
    " \n",
    "    while True:\n",
    "        response = langfuse.client.trace.list(\n",
    "            name=name, page=page, user_id=user_id\n",
    "        )\n",
    "        if not response.data:\n",
    "            break\n",
    "        page += 1\n",
    "        all_data.extend(response.data)\n",
    "        if len(all_data) > limit:\n",
    "            break\n",
    " \n",
    "    return all_data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    " \n",
    "NUM_TRACES_TO_SAMPLE = 3\n",
    "traces = get_traces(name='rag', limit=5)\n",
    "traces_sample = sample(traces, NUM_TRACES_TO_SAMPLE)\n",
    " \n",
    "len(traces_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score on a sample\n",
    "from random import sample\n",
    " \n",
    "evaluation_batch = {\n",
    "    \"question\": [],\n",
    "    \"contexts\": [],\n",
    "    \"answer\": [],\n",
    "    \"trace_id\": [],\n",
    "}\n",
    " \n",
    "for t in traces_sample:\n",
    "    observations = [langfuse.client.observations.get(o) for o in t.observations]\n",
    "    for o in observations:\n",
    "        if o.name == 'retrieval':\n",
    "            question = o.input['question']\n",
    "            contexts = o.output['contexts']\n",
    "        if o.name=='generation':\n",
    "            answer = o.output['answer']\n",
    "    evaluation_batch['question'].append(question)\n",
    "    evaluation_batch['contexts'].append(contexts)\n",
    "    evaluation_batch['answer'].append(answer)\n",
    "    evaluation_batch['trace_id'].append(t.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 6/6 [00:09<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# run ragas evaluate\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    " \n",
    "ds = Dataset.from_dict(evaluation_batch)\n",
    "r = evaluate(ds, metrics=[faithfulness, answer_relevancy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to deposit a cheque issued to an associate...</td>\n",
       "      <td>[Just have the associate sign the back and the...</td>\n",
       "      <td>\\nThe best way to deposit a cheque issued to a...</td>\n",
       "      <td>29d4ab60-82cb-435a-9ee5-dd992e13fa5a</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.941574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to deposit a cheque issued to an associate...</td>\n",
       "      <td>[Just have the associate sign the back and the...</td>\n",
       "      <td>\\nThe best way to deposit a cheque issued to a...</td>\n",
       "      <td>933e5b67-2a06-48e9-812d-3604867bf4c4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.941582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to deposit a cheque issued to an associate...</td>\n",
       "      <td>[Just have the associate sign the back and the...</td>\n",
       "      <td>\\nThe best way to deposit a cheque issued to a...</td>\n",
       "      <td>6f909d17-b73a-43ff-97fe-f4dd90b01de7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.941582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to deposit a cheque issued to an associate...   \n",
       "1  How to deposit a cheque issued to an associate...   \n",
       "2  How to deposit a cheque issued to an associate...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Just have the associate sign the back and the...   \n",
       "1  [Just have the associate sign the back and the...   \n",
       "2  [Just have the associate sign the back and the...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\nThe best way to deposit a cheque issued to a...   \n",
       "1  \\nThe best way to deposit a cheque issued to a...   \n",
       "2  \\nThe best way to deposit a cheque issued to a...   \n",
       "\n",
       "                               trace_id  faithfulness  answer_relevancy  \n",
       "0  29d4ab60-82cb-435a-9ee5-dd992e13fa5a           0.6          0.941574  \n",
       "1  933e5b67-2a06-48e9-812d-3604867bf4c4           0.6          0.941582  \n",
       "2  6f909d17-b73a-43ff-97fe-f4dd90b01de7           0.6          0.941582  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = r.to_pandas()\n",
    " \n",
    "# add the langfuse trace_id to the result dataframe\n",
    "df[\"trace_id\"] = ds[\"trace_id\"]\n",
    " \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    for metric_name in [\"faithfulness\", \"answer_relevancy\"]:\n",
    "        langfuse.score(\n",
    "            name=metric_name,\n",
    "            value=row[metric_name],\n",
    "            trace_id=row[\"trace_id\"]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
