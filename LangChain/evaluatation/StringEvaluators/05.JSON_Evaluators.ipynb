{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonValidityEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import JsonValidityEvaluator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "evaluator = JsonValidityEvaluator()\n",
    "# Equivalently\n",
    "# evaluator = load_evaluator(\"json_validity\")\n",
    "prediction = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'\n",
    "\n",
    "result = evaluator.evaluate_strings(prediction=prediction)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'reasoning': 'Expecting property name enclosed in double quotes: line 1 column 48 (char 47)'}\n"
     ]
    }
   ],
   "source": [
    "prediction = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\",}'\n",
    "result = evaluator.evaluate_strings(prediction=prediction)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonEqualityEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import JsonEqualityEvaluator\n",
    "\n",
    "evaluator = JsonEqualityEvaluator()\n",
    "# Equivalently\n",
    "# evaluator = load_evaluator(\"json_equality\")\n",
    "result = evaluator.evaluate_strings(prediction='{\"a\": 1}', reference='{\"a\": 1}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': False}\n"
     ]
    }
   ],
   "source": [
    "result = evaluator.evaluate_strings(prediction='{\"a\": 1}', reference='{\"a\": 2}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': False}\n"
     ]
    }
   ],
   "source": [
    "result = evaluator.evaluate_strings(prediction={\"a\": 1}, reference={\"a\": 2})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonEditDistanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.07692307692307693}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import JsonEditDistanceEvaluator\n",
    "\n",
    "evaluator = JsonEditDistanceEvaluator()\n",
    "# Equivalently\n",
    "# evaluator = load_evaluator(\"json_edit_distance\")\n",
    "\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction='{\"a\": 1, \"b\": 2}', reference='{\"a\": 1, \"b\": 8}'\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# The values are canonicalized prior to comparison\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction=\"\"\"\n",
    "    {\n",
    "        \"b\": 3,\n",
    "        \"a\":   1\n",
    "    }\"\"\",\n",
    "    reference='{\"a\": 1, \"b\": 3}',\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.18181818181818182}\n"
     ]
    }
   ],
   "source": [
    "# リストは順序を維持する。しかし、\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction='{\"a\": [1, 2]}', reference='{\"a\": [2, 1]}'\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "# オブジェクトを直接渡すこともできます。\n",
    "result = evaluator.evaluate_strings(prediction={\"a\": 1}, reference={\"a\": 2})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonSchemaEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import JsonSchemaEvaluator\n",
    "\n",
    "evaluator = JsonSchemaEvaluator()\n",
    "# Equivalently\n",
    "# evaluator = load_evaluator(\"json_schema_validation\")\n",
    "\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction='{\"name\": \"John\", \"age\": 30}',\n",
    "    reference={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"integer\"}},\n",
    "    },\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': True}\n"
     ]
    }
   ],
   "source": [
    "result = evaluator.evaluate_strings(\n",
    "    prediction='{\"name\": \"John\", \"age\": 30}',\n",
    "    reference='{\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"integer\"}}}',\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': False, 'reasoning': \"<ValidationError: '30 is less than the minimum of 66'>\"}\n"
     ]
    }
   ],
   "source": [
    "result = evaluator.evaluate_strings(\n",
    "    prediction='{\"name\": \"John\", \"age\": 30}',\n",
    "    reference='{\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"},'\n",
    "    '\"age\": {\"type\": \"integer\", \"minimum\": 66}}}',\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
