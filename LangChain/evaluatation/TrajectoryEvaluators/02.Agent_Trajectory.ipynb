{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "evaluator = load_evaluator(\"trajectory\",llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import HttpUrl\n",
    "\n",
    "\n",
    "@tool\n",
    "def ping(url: str, return_error: bool) -> str:  # HttpUrl -> str\n",
    "    \"\"\"Ping the fully specified url. Must include https:// in the url.\"\"\"\n",
    "    hostname = urlparse(url).netloc  # str(url) -> url\n",
    "    completed_process = subprocess.run(\n",
    "        [\"ping\", \"-c\", \"1\", hostname], capture_output=True, text=True\n",
    "    )\n",
    "    output = completed_process.stdout\n",
    "    if return_error and completed_process.returncode != 0:\n",
    "        return completed_process.stderr\n",
    "    return output\n",
    "\n",
    "\n",
    "@tool\n",
    "def trace_route(url: str, return_error: bool) -> str:  # HttpUrl -> str\n",
    "    \"\"\"Trace the route to the specified url. Must include https:// in the url.\"\"\"\n",
    "    hostname = urlparse(url).netloc  # str(url) -> url\n",
    "    completed_process = subprocess.run(\n",
    "        [\"traceroute\", hostname], capture_output=True, text=True\n",
    "    )\n",
    "    output = completed_process.stdout\n",
    "    if return_error and completed_process.returncode != 0:\n",
    "        return completed_process.stderr\n",
    "    return output\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    tools=[ping, trace_route],\n",
    "    agent=AgentType.OPENAI_MULTI_FUNCTIONS,\n",
    "    return_intermediate_steps=True,  # IMPORTANT!\n",
    ")\n",
    "\n",
    "result = agent(\"What's the latency like for https://langchain.com?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'reasoning': \"Let's evaluate the AI language model's answer based on the provided criteria:\\n\\ni. **Is the final answer helpful?**\\n   - Yes, the final answer provides a specific latency measurement (approximately 9.848 ms) for the website in question, along with information about packet loss, which is relevant and useful for understanding the site's responsiveness.\\n\\nii. **Does the AI language model use a logical sequence of tools to answer the question?**\\n   - Yes, the model used the ping tool, which is appropriate for measuring latency. The sequence is logical as it directly addresses the user's question about latency.\\n\\niii. **Does the AI language model use the tools in a helpful way?**\\n   - Yes, the model effectively utilized the ping tool to gather the necessary data about latency. The output from the ping command was correctly interpreted and presented in the final answer.\\n\\niv. **Does the AI language model use too many steps to answer the question?**\\n   - No, the model used a single step to obtain the latency information. This is efficient and appropriate for the question asked.\\n\\nv. **Are the appropriate tools used to answer the question?**\\n   - Yes, the ping tool is the appropriate tool for measuring latency, and it was used correctly.\\n\\n**Judgment:** The AI language model performed well in this instance. The final answer was helpful, the tool was used logically and effectively, and the process was efficient. Therefore, I would give the model a score of 5.\\n\\n**\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result = evaluator.evaluate_agent_trajectory(\n",
    "    prediction=result[\"output\"],\n",
    "    input=result[\"input\"],\n",
    "    agent_trajectory=result[\"intermediate_steps\"],\n",
    ")\n",
    "evaluation_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
